GC評価について（テスト②時点）

ヒープ設定：

現行(6/xx)のアクセス数とJDBC処理時間から、次期基盤のヒープ設定を以下のパターンに分けて設定している。

・パターン１：
	ヒープサイズ：1GB、コンテナサイズ：1.2GB
・パターン２：
	ヒープサイズ：1.6GB、コンテナサイズ：2GB

次期基盤は、プロセス構成的に、現行と比較してメモリ使用効率は悪い構成なので、現行よりはメモリを消費することは想定内。
例えば、現行はFullGCの発生は1日あるかないか程度であるが、
次期基盤は増加するので、目安感を情シスと協議する必要があるかもしれない。
ただし、現行APサーバはリソース的にかなり余裕があるので、それと同程度の諸元のWorkerノードなので、
JavaVMのメモリ割当を増やすことで現行に近いGC発生状況にすることは可能とは考えるが、
本番リリース後に実機で動作させながらのチューニングになると考える。


テスト環境での評価：

現状のテスト環境のGC発生状況については「gc.xlsx」参照のこと。

なお、2/28以降、NCI系のtomcatはヒープサイズの固定化をおこなっており、
また、reloadable=trueのため必要以上のGCが発生しているので、今回の評価対象外。

基本的には、GC処理時間では最大0.37秒（spring-nci-wf-mobile-ns）、FullGCで最大1.16秒（spring-sal）なので、
一般的には問題ないレベル。
また、メモリの回収も、うまく行われているようなので、メモリリークなどの懸念はないと思われる。
可能性として、指定したヒープサイズに達していないtomcatはメモリに余裕があるので、
万が一、今後Worker全体のメモリ不足が発生した場合はヒープの縮小が可能。


テスト環境は、本番移行後と比較して、ユーザ数も少なく負荷が低いので、少なくともGCの発生回数は低い。
以下に、負荷試験や本番移行後で負荷増によるパフォーマンス劣化が起きた場合の対策案（一般論ではあるが）記載しておく。

・GCの発生回数
GCが多い場合は、基本的にはNEW領域のサイズを増やすことであるが、メモリ回収がうまく動作しているようなので、
EdenとSuveriverの比率、Surviverの使用率を変更するだけでも十分かもしれない
現時点でも「ptl」には、この傾向があり。（もしかしたら「sal」も）

・FullGCの発生回数
基本的には、GCの発生回数を減らせば、FullGC回数も減るものと思われるが、減らない場合にはOLD領域を拡張する。
ちなみに、FullGCの発生回数が多い場合は、GC戦略をCMSやG1GCに変更することを推奨。
現時点では「esales」に、この傾向があり。注意すること。

・Metaspaceについて：
「kbs」のMetaspaceサイズが比較的高いこと。（大きな帳票などを扱っている？）
一応、Metaspaceサイズは200MB程度なので、今後コンテナがkillされる現象が発生する場合は、コンテナのメモリサイズを増やす。
業務処理的にメモリ負荷が高いと想定される場合は「kbs」はパターン２の設定に変更したほうが良いかもしれない。


その他システム全体の懸念点：

・レスポンスの低下
GCよる停止（Stop The World）に依存しないシステム全体のレスポンス低下が発生する場合、
nfsが原因の可能性があるので、Workerノードのcpu wait比率を確認すること。
結果、io wait値が高い場合は、ファイルサーバへのアクセスを減らす工夫をする。（多分、構成の変更を伴うかも？）

・拡張性
性能とは関係ないが、今回の次期基盤は拡張性がない。
例えば、Workerを追加したいとか、別のシステムを同居させる場合、ネットワーク設計をやり直す必要があるので注意すること。


以上
